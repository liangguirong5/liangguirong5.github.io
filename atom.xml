<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>RichardBai&#39;s Note</title>
  <subtitle>NLP水硕在读 | 白塔庵站街的日常</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://github.com/"/>
  <updated>2017-03-20T08:58:31.000Z</updated>
  <id>http://github.com/</id>
  
  <author>
    <name>Richard Bai</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ImageCaption从入门到放弃之三_ 强化学习</title>
    <link href="http://github.com/2017/03/16/ImageCaption%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83%E4%B9%8B%E4%B8%89-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/"/>
    <id>http://github.com/2017/03/16/ImageCaption从入门到放弃之三-强化学习/</id>
    <published>2017-03-15T16:22:51.000Z</published>
    <updated>2017-03-20T08:58:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>因为传统的seq2seq模型存在exposure bias（训练的时候，不论前一时刻的生成词是什么，总把期望的标签词作为当前时刻的输入；而测试时，使用前一时刻的生成词作为当前时刻的输入，这种现象就是exposure bias），而且优化的也不是整个序列的出现概率，而是每个词的出现概率，参见：<a href="https://liangguirong5.github.io/2017/03/12/ImageCaption从入门到放弃之二_attention机制/" target="_blank" rel="external">ImageCaption从入门到放弃之二_attention机制</a></p>
<p>因此第一篇文章提出用强化学习直接优化最终的生成序列的metrix分数，避免了上面的两个问题；第二篇文章是对第一篇的改进，目前在MSCOCO上的caption评测分数最高。</p>
<a id="more"></a>
<h1 id="sequence-level-training-with-recurrent-neural-networks"><a href="#Sequence-Level-Training-with-Recurrent-Neural-Networks" class="headerlink" title="Sequence Level Training with Recurrent Neural Networks"></a>Sequence Level Training with Recurrent Neural Networks</h1><p>XENT：最小化交叉熵的序列生成，上面两个问题都存在，尤其是exposure bias。模型结构见下图，就是最原始的带attetion的seq2seq模型。</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdp1tcrau7j30vc0lcq5o.jpg" alt=""></p>
<p>DAD：随机选择下一时刻的输入是标签or上一时刻的输出，是一种退火的思路，刚开始用样本的标签来训练这个模型，随着训练的深入，逐渐减小这个用标签训练的概率，直至最后模型完全不需要标签样本。存在的问题是，反传的时候不知道当前的输出是怎么产生的，这样有很多不能解释的地方。</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdp1totgqoj30wg09ujsm.jpg" alt=""></p>
<p>E2E：对beam search的改进，直接取输出层前k个最大的词，重新归一化他们的权重，然后进行加权求和，这个得到的融合词作为下一时刻的输入。实际操作时，还是退火方法训练。</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdp1usfepuj30y20ao3zt.jpg" alt=""></p>
<p>MIXER：这是本文提出的方法，mix XENT and RL的简写，强化学习的模型agent是decoder，状态s是当前的输入$x<em>t$和$h</em>{t-1}$，policy则是RNN内部的各个参数，action是每次预测出来的词，reward是计算出来的metrix分值。因为最后用一整串词来计算metrix分数，例如BLEU值，因此需要用policy gradient来进行模型的学习，损失函数如下：<br>$$<br>L<em>\theta=-\sum</em>{w_1^g,…,w<em>T^g}p</em>\theta(w_1^g,…,w_T^g)r(w_1^g,…,w<em>T^g)=-E</em>{[w_1^g,…,w_T^g]\sim p(\theta)}r(w_1^g,…,w<em>T^g)<br>$$<br>也就是生成序列长度为T，他的概率乘上对应的回报需要最大化，对应于上面的损失函数最小化。然后涉及到对这个函数进行求导，参考前人的工作得到<br>$$<br>\frac{\partial L</em>\theta}{\partial \theta}=\sum<em>t\frac{\partial L</em>\theta}{\partial o_t}\frac{\partial o_t}{\partial \theta}<br>$$<br>其中，$o<em>t$是softmax层的输入，然后有<br>$$<br>\frac{\partial L</em>\theta}{\partial o_t}=(r(w_1^g,…,w<em>T^g)-\widetilde{r}</em>{t+1})(p<em>{\theta}(w</em>{t+1}|w_t^g,h(t+1),c<em>t)-1(w</em>{t+1}^g))<br>$$</p>
<p>其中，$\widetilde{r}_{t+1}$是一个baseline，表示一个标准的回报值。如果我们生成的序列reward高，那第一个括号项就是正数，否则为负数，从而在这个式子中决定梯度的方向。第二个括号项就是梯度方向，是输出与标签的差（我们把t+1时刻的输出作为伪标签），之所以这么写，可以回想逻辑回归里面的梯度计算，误差函数求导之后就是这两项的差。我们这种计算梯度的方式，就是强化学习中的 policy gradient，如果不理解这个公式请看下面这一段，懂得可以跳过：</p>
<p>我们不知道生成序列的每一步的reward，但是我们知道最终这个序列的reward（BLEU、ROUGE等分数），这样如果最终reward高（对应上式第一个括号项大于零），那么我们的伪标签就是positive的，我们希望产生这样的结果，伪标签也就一定程度的变“真”了，这时直接沿着梯度下降去更新参数即可，且更新的幅度和reward大小成正比；如果最终reward很不理想，导致第一个括号项为负，那么再进行梯度下降去优化，就会得到相反的效果（max损失函数），使得输出离伪标签更远（这时伪标签是negative的），达到我们的本意。</p>
<p>在实际中，我们的字典很大，意味着action space很大，直接进行RL训练很难进行，因此作者提出预训练+退火：</p>
<p>前$N^{XENT}$个epochs用ground truth进行训练，损失函数采用交叉熵；然后$N^{XE+R}$个epochs中，前$T-\Delta$步进行XENT训练，后$\Delta$步进行Reinforce训练。算法和结构框图如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Data: a set of sequences with their corresponding context.</div><div class="line">Result: RNN optimized for generation.</div><div class="line">Initialize RNN at random and set N_XENT,N_XE+R and Delta;</div><div class="line">for s=T,1,-Delta do </div><div class="line">	if s==T then</div><div class="line">		train RNN for N_XENT epochs using XENT only;</div><div class="line">	else</div><div class="line">		train RNN for N_XE+R epochs. Use XENT loss in the first s 			steps, and RL in the remaining T-s steps.</div><div class="line">	end</div><div class="line">end</div></pre></td></tr></table></figure>
<p><img src="https://ww1.sinaimg.cn/large/006tNc79ly1fdp1v5gpb4j30z009egmz.jpg" alt=""></p>
<h1 id="self-critical-sequence-training-for-image-captioning"><a href="#Self-critical-Sequence-Training-for-Image-Captioning" class="headerlink" title="Self-critical Sequence Training for Image Captioning"></a>Self-critical Sequence Training for Image Captioning</h1><p>细心阅读会发现，上文提到的$\widetilde{r}_{t+1}$并没有说明是怎么确定的，在该论文中只是说他们用RNN的隐状态作为一个线性回归模型输入，去预测未来的reward，理论依据不足。因此，本篇论文就这一点完善了上文的工作。</p>
<p>本文提出了SCST(Self-critical Sequence Training )训练方式，利用当前模型去跑一遍解码过程，得到的评测分数作为baseline，参与强化学习训练中，下面这个图更有助于理解：</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdtd1qyovcj312y0jcadn.jpg" alt=""></p>
<p>效果图</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdtepb6turj30qa0agabz.jpg" alt=""></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>SCST是目前表现最好的模型，他每一次的标准reward是由相似的模型解码得到的，是不是可以用GAN来进行改进呢？此外，能不能设计一个模型，生成每一步的reward呢？这样不仅能加快训练，效果肯定也有提升。最后，关于DQN和PG的优劣，可能会单独发一篇博文来好好整理一下。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为传统的seq2seq模型存在exposure bias（训练的时候，不论前一时刻的生成词是什么，总把期望的标签词作为当前时刻的输入；而测试时，使用前一时刻的生成词作为当前时刻的输入，这种现象就是exposure bias），而且优化的也不是整个序列的出现概率，而是每个词的出现概率，参见：&lt;a href=&quot;https://liangguirong5.github.io/2017/03/12/ImageCaption从入门到放弃之二_attention机制/&quot;&gt;ImageCaption从入门到放弃之二_attention机制&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;因此第一篇文章提出用强化学习直接优化最终的生成序列的metrix分数，避免了上面的两个问题；第二篇文章是对第一篇的改进，目前在MSCOCO上的caption评测分数最高。&lt;/p&gt;
    
    </summary>
    
      <category term="Caption" scheme="http://github.com/categories/Caption/"/>
    
    
      <category term="caption" scheme="http://github.com/tags/caption/"/>
    
      <category term="RL" scheme="http://github.com/tags/RL/"/>
    
  </entry>
  
  <entry>
    <title>ImageCaption从入门到放弃之二_attention机制</title>
    <link href="http://github.com/2017/03/12/ImageCaption%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83%E4%B9%8B%E4%BA%8C_attention%E6%9C%BA%E5%88%B6/"/>
    <id>http://github.com/2017/03/12/ImageCaption从入门到放弃之二_attention机制/</id>
    <published>2017-03-12T12:55:43.000Z</published>
    <updated>2017-03-20T02:24:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>前一篇文章<a href="https://liangguirong5.github.io/2017/03/01/image_caption/" target="_blank" rel="external">ImageCaption从入门到放弃之一_任务综述</a>介绍了传统的基于seq2seq的caption模型，这个模型来自机器翻译，因此机器翻译中的attetion机制在我们的caption任务中也可以借鉴，很多论文就是围绕这个attention该怎么加而展开的，我们主要介绍下面两篇比较有代表性的论文：</p>
<a id="more"></a>
<p>Xu, K., &amp; Bengio, Y. (2016, April 20). Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. <em>arXiv.org</em>.</p>
<p>Lu, J., &amp; Socher, R. (2016, December 7). Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning. <em>arXiv.org</em>.</p>
<p>注意：这个两篇文章的符号不统一，请注意区分。</p>
<h1 id="neural-image-caption-generation-with-visual-attention"><a href="#Neural-Image-Caption-Generation-with-Visual-Attention" class="headerlink" title="Neural Image Caption Generation with Visual Attention"></a>Neural Image Caption Generation with Visual Attention</h1><p>第一篇论文是Bengio课题组的一份工作，主要是在seq2seq进行image caption的基础上，引入attention机制，强调生成caption时，不同时刻的关注点应该在不同的图像区域。 下图是模型的整体框架。</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdkdc2lxybj31gq0o6afg.jpg" alt=""></p>
<p>其中，encoder部分是一个卷积网络，目的是获取原图像的L个特征，每个特征是一个D维的向量，用以表示原图的某一部分。<br>$$<br>a={a_1,…,a_L}, a_i\in R^D<br>$$<br>decoder部分是一个LSTM，叠加使用了attention机制。本文的分别使用了hard和soft两种attention。</p>
<h2 id="stochastic-hard-attention"><a href="#Stochastic-“Hard”-attention" class="headerlink" title="Stochastic “Hard” attention"></a>Stochastic “Hard” attention</h2><p>用t表示生成第t个词的时刻，$s_{t,i}$是一个布尔量，表示第t时刻第i个图像特征$a<em>i$是否为注意力特征，服从多元伯努利分布，如下式所示<br>$$<br>p(s</em>{t,i}=1|s<em>{j&lt;t},a)=\alpha</em>{t,i}<br>$$</p>
<p>$$<br>z_t = \sum<em>is</em>{t,i}a_i<br>$$</p>
<p>其中，$z_t$表示经过attention机制后融合图像特征，作为LSTM的输入。</p>
<p>我们要优化的是$log\ p(y|a)$，想让它尽可能的大，那可以通过构造一个和$s$有关的下界$L_s$，最大化$L_s$即可最大化$log\ p(y|a)$，<br>$$<br>L_s = \Sigma_sp(s|a)log\ p(y|s,a)&lt;=log\Sigma_sp(s|a)p(y|s,a)=log\ p(y|a)<br>$$<br>这样反传的时候，求导数就有</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdl6m491kuj30j006iq3i.jpg" alt=""></p>
<p>这里面s服从多元伯努利分布，<br>$$<br>s_t \sim Multinoulli_L({\alpha_i})<br>$$<br>因此前面的导数公式可以用N次蒙特卡洛采样近似，即</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdl6qs71mwj30ik060dgf.jpg" alt=""></p>
<p>最后，引入了一个平均阈值项b和多元伯努利分布的熵项H，来减小上面梯度计算的方差，最终的公式为</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdl6xtphfcj30km05qq3q.jpg" alt=""></p>
<p>$\lambda_r$和$\lambda_e$分别是交叉验证的参数。（此处黑人问号，待参考：Multiple object recognition with visual attention）</p>
<h2 id="deterministic-soft-attention"><a href="#Deterministic-“Soft”-Attention" class="headerlink" title="Deterministic “Soft” Attention"></a>Deterministic “Soft” Attention</h2><p>所谓soft，就是不引入上面的s来决定哪个图像特征需要被关注，而是每个图像特征都按照原本的被关注的概率进行期望求和，得到我们需要的输入Z。<br>$$<br>z_t = \sum<em>i^L\alpha</em>{t,i}a_i<br>$$<br>值得注意的是，$\sum<em>i\alpha</em>{ti}=1$是不会变的，因为我们是通过softmax得到的$\alpha$。我们再令$\sum<em>t\alpha</em>{ti}\approx1$，这是为了鼓励模型在整个句子生成的期间内，虽然每个特征被注意的时刻不同，但是每个特征总有一些时刻被着重注意了，也就是每个特征都有用，不能从头到尾都和生成的词无关。</p>
<p>又引入了一个scalar $\beta$，使$z_t =\beta \sum<em>i^L\alpha</em>{t,i}a_i$，$\beta<em>t=\sigma(f</em>\beta(h_{t-1}))$，没什么理由，只是单纯实验发现这样做能让注意力集中在图像中的目标上。</p>
<p>最后，最小化下面的带惩罚项的损失函数。</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79gy1fdl870l391j30h602wq35.jpg" alt=""></p>
<h1 id="knowing-when-to-look-adaptive-attention-via-a-visual-sentinel-for-image-captioning"><a href="#Knowing-When-to-Look-Adaptive-Attention-via-A-Visual-Sentinel-for-Image-Captioning" class="headerlink" title="Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning"></a>Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning</h1><p>这篇文章是上一篇的改进，出发点在于不需要每个词的生成都对应一个attetion，一些介词和连词并不需要图像中的信息，因此，本文提出attention的时间和空间的概念。</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdlpl501wbj30so0cuab1.jpg" alt=""></p>
<p>原始的模型如上图（a），这个模型就是刚刚那篇论文的模型。本文对其首先进行如图（b）的改进，使得每次的attention根据当前的h而不是上一时刻的h来生成。其中，$x<em>t$是$y</em>{t-1}$的词向量。</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdlpncja9kj30om0e4abg.jpg" alt=""></p>
<p>其次，引入了visual sentinel视觉哨兵，什么意思呢？</p>
<p>原始的经过CNN提取到的特征是$v_1….v_L$，每次计算attention权重$\alpha$的时候，我们用下面的公式<br>$$<br>z_t = w_h^Ttanh(W_vV+W_gh_tI^T)\\alpha_t = softmax(z_t)<br>$$</p>
<p>其中，V是d*k维，表示k个图像特征；$h_t$是第t时刻的decoder的隐状态输出，是d*1维，$w_h是k*1维的参数，两个W是k*d维的参数。</p>
<p>当引入视觉哨兵时，看上面的图，除了L个v向量，多了一个s向量，这个s的定义是</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdm4wfurm8j30ga03q74l.jpg" alt=""></p>
<p>可以看出，g是一个门系数，他由上一时刻的隐状态和当前的输入（前一个单词）决定，这个g控制当前的记忆m，记忆就是LSTM的记忆门输出，他包含了截止到目前的语义信息和图像信息。 上面的两个公式可以理解为：根据前一时刻的状态和输入，对当前的记忆进行加工（点乘），加工后的向量称作哨兵信息。</p>
<p>这个哨兵信息作为和CNN的图像特征v一起，进行attention计算，如果attention的重点在s哨兵，说明当前不需要关注图像信息，当前的输出单词可能是介词、连词之类的词。所以，新的attention系数公式如下。</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdm59gq97lj30nm02uq3b.jpg" alt=""></p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdmgtyl5b4j30bc02mwek.jpg" alt=""></p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdm5f6tytxj30d802cmx7.jpg" alt=""></p>
<p>从而得到新的context信息。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这两篇论文都是对attention进行研究和改进，本质上还是没有解决exposure bias问题，而且原始的seq2seq用每一步生成单词的概率进行连乘，作为整个序列的概率，这一点也可以改进，下一文会介绍如何用强化学习来解决这两个问题。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前一篇文章&lt;a href=&quot;https://liangguirong5.github.io/2017/03/01/image_caption/&quot;&gt;ImageCaption从入门到放弃之一_任务综述&lt;/a&gt;介绍了传统的基于seq2seq的caption模型，这个模型来自机器翻译，因此机器翻译中的attetion机制在我们的caption任务中也可以借鉴，很多论文就是围绕这个attention该怎么加而展开的，我们主要介绍下面两篇比较有代表性的论文：&lt;/p&gt;
    
    </summary>
    
      <category term="Caption" scheme="http://github.com/categories/Caption/"/>
    
    
      <category term="caption" scheme="http://github.com/tags/caption/"/>
    
      <category term="seq2seq" scheme="http://github.com/tags/seq2seq/"/>
    
  </entry>
  
  <entry>
    <title>NIPS 2016 Tutorial Generative Adersarial Networks</title>
    <link href="http://github.com/2017/03/09/NIPS%202016%20Tutorial%20Generative%20Adersarial%20Networks/"/>
    <id>http://github.com/2017/03/09/NIPS 2016 Tutorial Generative Adersarial Networks/</id>
    <published>2017-03-09T12:29:52.000Z</published>
    <updated>2017-03-18T09:30:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文是根据NIPS2016的tutorial翻译、总结的中文文档。</p>
<a id="more"></a>
<p>主要包括以下几个方面：</p>
<ol>
<li>生成模型的研究价值</li>
<li>生成模型的原理以及GAN同其他生成模型的区别</li>
<li>GAN的工作原理</li>
<li>GAN的前沿进展</li>
</ol>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>GAN是生成模型的一种，本文所指的生成模型，是根据服从$P<em>{data}$分布的样本集合，学习出这种分布的估计。学出来的分布称为$P</em>{model}$，也就是我们模型学出来的分布。一种生成模型的训练目标是去尽可能“精确”地估计数据的分布，如下图。</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdhtpqamgkj30v8072gm0.jpg" alt=""></p>
<p>另一种则是学着数据样本（按照$P_{model}$）去产生新的“样本”，我们的GAN模型倾向于执行这种任务。</p>
<p><img src="https://ww3.sinaimg.cn/large/006tNc79ly1fdhtqgeqp3j30ve0ayjtz.jpg" alt=""></p>
<h1 id="1生成模型的研究价值"><a href="#1-生成模型的研究价值" class="headerlink" title="1.生成模型的研究价值"></a>1.生成模型的研究价值</h1><p>为什么要研究生成模型呢？特别是那种只能产生更多样本的，毕竟，世界上从来不缺少更多的图片。</p>
<p>其实，生成模型的重要性有以下几点：</p>
<ol>
<li><p>训练生成模型或是从生成模型采样，有助于评价我们表示、操作高维概率分布的能力，而这种能力恰恰是许多科学的基础。（私以为这点有点虚。。。）</p>
</li>
<li><p>生成模型可以被正整合强化学习当中（关键应用）</p>
<p>强化学习可以分为有模型和无模型的两类，有模型的就有一个生成模型，它生成的时序数据可以用于模拟未来，进而进行决策。具体来讲，给定当前状态和采取的动作，由生成模型去预测下一时刻状态的条件概率分布。我们的agent可以给生成模型几个候选的动作去查询，进而选择一个产生能期望状态且概率最大的动作去执行。</p>
<p>生成模型还可以被用于生成一个虚拟的环境供强化学习训练、指导RL的exploration，GAN可以用于inverse RL。</p>
</li>
<li><p>生成模型可以用缺失的数据训练，也能用有缺失的数据作为输入进行概率预测。GAN用于半监督学习就是典型的例子。</p>
</li>
<li><p>生成模型，特别是GANs，适合于multi-modal输出，也是就一个输入对应于多个正确答案。</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdhyqbksyaj30vu0ds75s.jpg" alt=""></p>
</li>
<li><p>许多任务的内在，都是需要产生样本的真实分布。例如下图最左面的一张为高分辨率原图，经过下采样可以产生低分辨率图像。不同的方法去对低分辨率图像进行还原，右面三张依次是插值法、神经网络MSE训练、GAN网络的效果。GAN的效果比MSE好，是因为它知道这个答案有多个解，只选其一即可，而MSE一般是取平均。</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdhyuw4uhdj30yq0fgaea.jpg" alt=""></p>
</li>
<li><p>辅助艺术创作、image to image translation，不多说，上图：</p>
<p><img src="https://ww4.sinaimg.cn/large/006tNc79ly1fdhzahf37kj316c0jyjxa.jpg" alt=""></p>
</li>
</ol>
<h1 id="2生成模型的原理以及gan同其他生成模型的区别"><a href="#2-生成模型的原理以及GAN同其他生成模型的区别" class="headerlink" title="2.生成模型的原理以及GAN同其他生成模型的区别"></a>2.生成模型的原理以及GAN同其他生成模型的区别</h1><h2 id="21-最大似然估计"><a href="#2-1-最大似然估计" class="headerlink" title="2.1 最大似然估计"></a>2.1 最大似然估计</h2><p>$$<br>θ^* =argmax<em>\theta\Sigma log p</em>{model}(x^{(i)};\theta)<br>$$</p>
<h2 id="22-生成模型分类树"><a href="#2-2-生成模型分类树" class="headerlink" title="2.2 生成模型分类树"></a>2.2 生成模型分类树</h2><p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdi1w0nejej30yy0piq75.jpg" alt=""></p>
<h2 id="23-explicit-desity-models"><a href="#2-3-explicit-desity-models" class="headerlink" title="2.3 explicit desity models"></a>2.3 explicit desity models</h2><p>这是一种直接最大化似然函数的模型，只需要把样本带入到概率公式中然后取似然相加求和，通过梯度法最大化即可。存在一个难点：保证computational tractability.</p>
<h3 id="231-tractable-explicit-models"><a href="#2-3-1-Tractable-explicit-models" class="headerlink" title="2.3.1 Tractable explicit models"></a>2.3.1 Tractable explicit models</h3><ol>
<li><p>Fully visible belief networks</p>
<p><img src="https://ww2.sinaimg.cn/large/006tNc79ly1fdi29zevfmj30j403udg1.jpg" alt=""></p>
</li>
<li><p>Nonlinear independent components analysis</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是根据NIPS2016的tutorial翻译、总结的中文文档。&lt;/p&gt;
    
    </summary>
    
      <category term="GAN" scheme="http://github.com/categories/GAN/"/>
    
    
      <category term="生成模型" scheme="http://github.com/tags/%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="GAN" scheme="http://github.com/tags/GAN/"/>
    
      <category term="Tutorial" scheme="http://github.com/tags/Tutorial/"/>
    
  </entry>
  
  <entry>
    <title>ImageCaption从入门到放弃之一_任务综述</title>
    <link href="http://github.com/2017/03/01/ImageCaption%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E6%94%BE%E5%BC%83%E4%B9%8B%E4%B8%80_%E4%BB%BB%E5%8A%A1%E7%BB%BC%E8%BF%B0/"/>
    <id>http://github.com/2017/03/01/ImageCaption从入门到放弃之一_任务综述/</id>
    <published>2017-03-01T12:29:52.000Z</published>
    <updated>2017-03-15T16:25:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>第二十二期的PaperWeekly对Image Captioning进行了综述。今天这篇文章中，我们会介绍一些近期的工作。（如果你对Image Captioning这个任务不熟悉的话，请移步二十二期<a href="http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247484014&amp;idx=1&amp;sn=4a053986f5dc8abb45097fed169465fa&amp;chksm=96e9ddeea19e54f83b717d63029a12715c238de8d6af261fa64af2d9b949480e685b8c283dda&amp;scene=21#wechat_redirect" target="_blank" rel="external">PaperWeekly 第二十二期—Image Caption任务综述</a>）</p>
<a id="more"></a>
<p>Image Captioning的模型一般是encoder-decoder的模型。模型对$p(S|I)$进行建模，$S$是描述，$I$是图片。模型的训练目标是最大化log似然：$\max_\theta\sum_i \log P(S_i|I_i, \theta)$。</p>
<p>然而使用最大似然训练有两个问题：</p>
<p>1、虽然训练时最大化后验概率，但是在评估时使用的测度则为BLEU，METEOR，ROUGE，CIDER等。这里有训练loss和评估方法不统一的问题。而且log似然可以认为对每个单词都给予一样的权重，然而实际上有些单词可能更重要一些（比如说一些表示内容的单词）。</p>
<p>2、第二个问题为Exposure bias。训练的时候，每个时刻的输入都是来自于真实的caption。而生成的时候，每个时刻的输入来自于前一时刻的输出；所以一旦有一个单词生成的不好，错误可能会接着传递，使得生成的越来越糟糕。</p>
<p>如何解决这两个问题呢？很显而易见的想法就是尽量使得训练和评估时的情形一样。我们可以在训练的时候不优化log似然，而是直接最大化CIDER（或者BLEU，METEOR，ROUGE等）。并且，在训练时也和测试时一样使用前一时刻的输入，而不是全使用ground truth输入。</p>
<p>然而这有什么难点呢？第一，CIDER或者这一些metric并不是可直接求导。（这就是为什么在分类问题中，我们把0-1 error近似成log loss，hinge loss的原因）。其次从前一时刻输出获得后一时刻的输入涉及到采样操作，这也是不可微的。为了能够解决这些不可微的问题，人们就想到了Reinforcement learning。</p>
<h1 id="rl基本概念"><a href="#RL基本概念" class="headerlink" title="RL基本概念"></a><strong>RL基本概念</strong></h1><p>RL中有一些比较重要的基本概念：状态（state），行为（action），回报（reward）和决策（policy）。决策是一个状态到动作的函数，一般是需要学习的东西。拿打游戏的例子介绍RL最简单。如果说是玩flappy bird，RL要学习的就是在什么位置跳，能使得最后得到的分数越高。在这个例子里，最后的分数就是回报，位置就是状态，跳或者不跳就是行为，而什么时候跳就是学到的策略。</p>
<p>如果放在Image captioning中，状态就是你看到的图片和已生成的单词，而动作就是下一个单词生成什么，回报就是CIDER等metric。</p>
<h2 id="相关文献"><a href="#相关文献" class="headerlink" title="相关文献"></a><strong>相关文献</strong></h2><p>最近已经有很多工作将RL用在NLP相关的问题上。[1]第一次将REINFORCE算法用在image caption和seq2seq问题上。[5]将使用了更先进的RL算法 — Actor-critic — 来做machine translation上。[2,4]将[1]的算法进行稍许改进（仍旧是REINFORCE算法），使用在了image captioning上。[3]将REINFORCE用在序列生成GAN中，解决了之前序列生成器输出为离散不可微的问题。[6]将RL用在自然对话系统中。这篇文章中我们主要介绍[1,2,4]。</p>
<h2 id="rl算法背景"><a href="#RL算法背景" class="headerlink" title="RL算法背景"></a><strong>RL算法背景</strong></h2><p>这三篇文章使用的是REINFORCE算法，属于增强学习中Policy Gradient的一种。我们需要将deterministic的策略形式 $a=\pi(s,\theta)$转化为概率形式，$p(a) = \pi(a|s, \theta)$。Policy Gradient就是对参数$\theta$求梯度的方法。</p>
<p>直观的想，如果我们希望最后的决策能获得更高的reward，最简单的就是使得高reward的行为有高概率，低reward的行为有低概率。所以REINFORCE的更新目标为</p>
<p>$$\max_{\theta} \sum R(a,s)\log \pi(a|s, \theta)$$</p>
<p>$R(s,a)$是回报函数。有了目标，我们可以通过随机梯度下降来更新$\theta$来获得更大的回报。</p>
<p>然而这个方法有一个问题，训练时梯度的方差过大，导致训练不稳定。我们可以思考一下，如果reward的值为100到120之间，现在的方法虽然能更大地提高reward为120的行为的概率，但是也还是会提升低reward的行为的概率。所以为了克服这个问题，又有了REINFORCE with baseline。</p>
<p>$$\max_{\theta} \sum (R(a,s) - b(s))\log \pi(a|s, \theta)$$</p>
<p>$b(s)$在这里就是baseline，目的是通过给回报一个基准来减少方差。假设还是100到120的回报，我们将baseline设为110，那么只有100回报的行为就会被降低概率，而120回报的行为则会被提升概率。</p>
<h1 id="三篇paper"><a href="#三篇paper" class="headerlink" title="三篇paper"></a><strong>三篇paper</strong></h1><p>第一篇是FAIR在ICLR2016发表的[1]。这篇文章是第一个将RL的算法应用的离散序列生成的文章。文章中介绍了三种不同的方法，这里我们只看最后一种算法，Mixed Incremental Cross-Entropy Reinforce。</p>
<p>大体的想法就是用REINFORCE with baseline来希望直接优化BLEU4分数。具体训练的时候，他们先用最大似然方法做预训练，然后用REINFORCE finetune。在REINFORCE阶段，生成器不再使用任何ground truth信息，而是直接从RNN模型随机采样，最后获得采样的序列的BLEU4的分数r作为reward来更新整个序列生成器。</p>
<p>这里他们使用baseline在每个时刻是不同的；是每个RNN隐变量的一个线性函数。这个线性函数也会在训练中更新。他们的系统最后能比一般的的cross extropy loss，和scheduled sampling等方法获得更好的结果。</p>
<p>他们在github开源了基于torch的代码，<a href="https://github.com/facebookresearch/MIXER">https://github.com/facebookresearch/MIXER</a></p>
<p>第二篇论文是今年CVPR的投稿。这篇文章在[1]的基础上改变了baseline的选取。他们并没有使用任何函数来对baseline进行建模，而是使用了greedy decoding的结果的回报作为baseline。他们声称这个baseline减小了梯度的variance。</p>
<p>这个baseline理解起来也很简单：如果采样得到句子没有greedy decoding的结果好，那么降低这句话的概率，如果比greedy decoding还要好，则提高它的概率。</p>
<p>这个方法的好处在于避免了训练一个模型，并且这个baseline也极易获得。有一个很有意思的现象是，一旦使用了这样的训练方法，beam search和greedy decoding的结果就几乎一致了。</p>
<p>目前这篇文章的结果是COCO排行榜上第一名。他们使用CIDEr作为优化的reward，并且发现优化CIDEr能够使所有其他metric如BLEU，ROUGE，METEOR都能提高。</p>
<p>他们的附录中有一些captioning的结果。他们发现他们的模型在一些非寻常的图片上表现很好，比如说有一张手心里捧着一个长劲鹿的图。</p>
<p>第三篇论文[4]也是这次CVPR的投稿。这篇文章则是在$R(a,s)$这一项动了手脚。</p>
<p>前两篇都有一个共同特点，对所有时刻的单词，他们的$R(a,s)$都是一样的。然而这篇文章则给每个时刻的提供了不同的回报。</p>
<p>其实这个动机很好理解。比如说，定冠词a，无论生成的句子质量如何，都很容易在句首出现。假设说在一次采样中，a在句首，且最后的获得回报减去baseline后为负，这时候a的概率也会因此被调低，但是实际上大多数情况a对最后结果的好坏并没有影响。所以这篇文章采用了在每个时刻用$Q(w_{1:t})$来代替了原来一样的$R$。</p>
<p>这个$Q$的定义为，</p>
<p>$Q\theta(w{1:t}) = \mathbb{E}{w{t+1:T}}[R(w{1:t}, w{t+1:T})]$</p>
<p>也就是说，当前时刻的回报，为固定了前t个单词的期望回报。考虑a的例子，由于a作为句首生成的结果有好有坏，最后的Q值可能接近于baseline，所以a的概率也就不会被很大地更新。实际使用中，这个Q值可以通过rollout来估计：固定前t个词后，随机采样K个序列，取他们的平均回报作为Q值。文中K为3。这篇文章中的baseline则跟[1]中类似。</p>
<p>从实验结果上，第三篇并没有第二篇好，但是很大一部分原因是因为使用的模型和特征都比较老旧。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h1><p>将RL用在序列生成上似乎是现在新的潮流。但是现在使用的大多数的RL方法还比较简单，比如本文中的REINFORCE算法可追溯到上个世纪。RL本身也是一个很火热的领域，所以可以预计会有更多的论文将二者有机地结合。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a><strong>参考文献</strong></h1><p>[1] Ranzato, Marc’Aurelio, Sumit Chopra, Michael Auli, and Wojciech Zaremba. “Sequence level training with recurrent neural networks.” arXiv preprint arXiv:1511.06732 (2015).</p>
<p>[2] Rennie, Steven J., Etienne Marcheret, Youssef Mroueh, Jarret Ross, and Vaibhava Goel. “Self-critical Sequence Training for Image Captioning.” arXiv preprint arXiv:1612.00563 (2016).</p>
<p>[3] Yu, Lantao, Weinan Zhang, Jun Wang, and Yong Yu. “Seqgan: sequence generative adversarial nets with policy gradient.” arXiv preprint arXiv:1609.05473 (2016).</p>
<p>[4] Liu, Siqi, Zhenhai Zhu, Ning Ye, Sergio Guadarrama, and Kevin Murphy. “Optimization of image description metrics using policy gradient methods.” arXiv preprint arXiv:1612.00370 (2016).</p>
<p>[5] Bahdanau, Dzmitry, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron Courville, and Yoshua Bengio. “An actor-critic algorithm for sequence prediction.” arXiv preprint arXiv:1607.07086 (2016).</p>
<p>[6] Li, Jiwei, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky. “Deep reinforcement learning for dialogue generation.” arXiv preprint arXiv:1606.01541 (2016).</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;第二十二期的PaperWeekly对Image Captioning进行了综述。今天这篇文章中，我们会介绍一些近期的工作。（如果你对Image Captioning这个任务不熟悉的话，请移步二十二期&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;amp;mid=2247484014&amp;amp;idx=1&amp;amp;sn=4a053986f5dc8abb45097fed169465fa&amp;amp;chksm=96e9ddeea19e54f83b717d63029a12715c238de8d6af261fa64af2d9b949480e685b8c283dda&amp;amp;scene=21#wechat_redirect&quot;&gt;PaperWeekly 第二十二期—Image Caption任务综述&lt;/a&gt;）&lt;/p&gt;
    
    </summary>
    
      <category term="Caption" scheme="http://github.com/categories/Caption/"/>
    
    
      <category term="caption" scheme="http://github.com/tags/caption/"/>
    
  </entry>
  
  <entry>
    <title>贝叶斯优化</title>
    <link href="http://github.com/2017/02/26/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%98%E5%8C%96/"/>
    <id>http://github.com/2017/02/26/贝叶斯优化/</id>
    <published>2017-02-26T05:52:29.000Z</published>
    <updated>2017-03-18T09:31:13.000Z</updated>
    
    <content type="html"><![CDATA[<p>贝叶斯优化可以用于复杂模型的调参过程中，可以自动确定一套表现最优的模型参数。本文是对贝叶斯优化方法的浅层解读，日后填坑~</p>
<a id="more"></a>
<h1 id="bayesian-optimization"><a href="#Bayesian-Optimization" class="headerlink" title="Bayesian Optimization"></a>Bayesian Optimization</h1><p>当对目标函数没有封闭形式的表达，但是可以得到目标函数在采样点的观测值时，可以用贝叶斯优化来寻找目标函数的极值。</p>
<p>优势在于需要较少的采样点，适合观测值costly的对象。</p>
<p>贝叶斯优化根据下面的acqusition function来选取下一个采样点的位置:<br>$$<br>x<em>t=argmax</em>{x \in D}\mu<em>{t-1}(x)+\beta^{1/2}\sigma</em>{t-1}(x)<br>$$<br>首先用已有观测值构建高斯过程回归模型，并预测输入位置上的未知函数值服从的的高斯分布，得到该点均值和方差，即$\mu<em>{t-1}(x)$和$\sigma</em>{t-1}(x)$。上式的$\beta_t$是一个权重参数，具体设置参见论文：Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design.</p>
<p>这个公式描述的是，如果标准差大，表示我们对该点了解程度小，值得探索(exploration)；如果均值大，表明该点可能就是我们要找的最大值点，值得开发(exploitation)。一开始，我们的采样数据很少，算法会去采样标准差很大的点；当采样的点多了，标准差会降低，算法偏向于去均值大的点，最终收敛到全局最优值。</p>
<h1 id="gaussian-process-regression"><a href="#Gaussian-Process-Regression" class="headerlink" title="Gaussian Process Regression"></a>Gaussian Process Regression</h1><p>关于高斯过程回归的知识可以参考下面两个链接，互为补充。</p>
<p><a href="http://blog.sina.com.cn/s/blog_5033f3b40102vts4.html" target="_blank" rel="external">高斯过程回归</a></p>
<p><a href="http://www.kuqin.com/shuoit/20150508/345958.html" target="_blank" rel="external">说说高斯过程回归</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;贝叶斯优化可以用于复杂模型的调参过程中，可以自动确定一套表现最优的模型参数。本文是对贝叶斯优化方法的浅层解读，日后填坑~&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://github.com/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="http://github.com/tags/DeepLearning/"/>
    
      <category term="模型调参" scheme="http://github.com/tags/%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/"/>
    
  </entry>
  
  <entry>
    <title>五年梯度三年下降</title>
    <link href="http://github.com/2017/02/20/%E4%BA%94%E5%B9%B4%E6%A2%AF%E5%BA%A6%E4%B8%89%E5%B9%B4%E4%B8%8B%E9%99%8D/"/>
    <id>http://github.com/2017/02/20/五年梯度三年下降/</id>
    <published>2017-02-20T12:29:52.000Z</published>
    <updated>2017-03-19T08:28:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>梯度下降，是当下最常见的神经网络参数调优算法。当我们需要最小化目标函数$J(\theta)$时，只需要沿着目标函数梯度的$\nabla_\theta J(\theta)$反方向去更新$\theta$，就能让目标函数越来越小。如果$J(\theta)$是凸函数（二次导数非负），那最后一定能收敛到全局最小值，否则可能收敛到局部最小值。</p>
<a id="more"></a>
<p>梯度下降的原理，学过二次函数曲线的高中生就看懂，不过也可以用泰勒展开加以证明：<br>$$<br>J(\theta+\Delta\theta) \approx J(\theta)+\nabla<em>\theta J(\theta)\Delta\theta<br>$$<br>我们要求每次更新$J$都要减小，所以必然有$J(\theta+\Delta\theta) - J(\theta)&lt;0$，进而要求展式的一阶项恒小于零，可选择令<br>$$<br>\Delta\theta = -\alpha\nabla</em>\theta J(\theta)<br>$$<br>其中，步长$\alpha$是一个小的正常数，这就是梯度下降法。</p>
<p>如果把上面的泰勒展式写到二阶项：<br>$$<br>J(\theta+\Delta\theta) \approx J(\theta)+\nabla<em>\theta J(\theta)\Delta\theta+\nabla</em>{\theta}^2 J(\theta)\Delta\theta^2<br>$$<br>就可以推导出牛顿法，步长更新是一阶导与二阶导的比值的相反数。</p>
<h1 id="三类梯度下降"><a href="#三类梯度下降" class="headerlink" title="三类梯度下降"></a>三类梯度下降</h1><p>三种梯度下降区别在于：选择用多少数据来计算目标函数的梯度。</p>
<h2 id="batch-gradient-descent"><a href="#Batch-gradient-descent" class="headerlink" title="Batch gradient descent"></a>Batch gradient descent</h2><p>又称Vanilla gradient descend，根据整个训练样本集来更新参数$\theta$,<br>$$<br>θ=θ−η⋅∇θJ(θ)<br>$$<br>因为我们每次更新都需要整个训练数据集参与计算，所以速度很慢，如果训练样本很多以至于不能放在内存，这种方法便无计可施了。此外，batch梯度法不能在线更新权值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</div><div class="line">  params_grad = evaluate_gradient(loss_function, data, params)</div><div class="line">  params = params - learning_rate * params_grad</div></pre></td></tr></table></figure>
<h2 id="stochastic-gradient-descent"><a href="#Stochastic-gradient-descent" class="headerlink" title="Stochastic gradient descent"></a>Stochastic gradient descent</h2><p>SGD即为随机梯度下降，每次权值更新只用到一个训练样本：<br>$$<br>θ=θ−η⋅∇θJ(θ;x(i);y(i))<br>$$<br>相比于batch方法，我们的SGD小朋友每次只用一个样本，及时更新权重，因此收敛的会更快，可以用于在线学习。SGD在训练中会表现出周期性的波动，如下图所示。</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/f/f3/Stogra.png" alt=""></p>
<p>这种抖动一方面使得训练中可以跳出局部最小，从而进入更好的位置进行梯度下降；另一方面可能造成收敛的难度加大，因为SGD总是容易冲过头。</p>
<p>但是如果慢慢的减小学习率的话，SGD还是可以同batch一样的收敛的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</div><div class="line">  np.random.shuffle(data)</div><div class="line">  <span class="keyword">for</span> example <span class="keyword">in</span> data:</div><div class="line">    params_grad = evaluate_gradient(loss_function, example, params)</div><div class="line">    params = params - learning_rate * params_grad</div></pre></td></tr></table></figure>
<h2 id="mini-batch-gradient-descent"><a href="#Mini-batch-gradient-descent" class="headerlink" title="Mini-batch gradient descent"></a>Mini-batch gradient descent</h2><p>随机多样本梯度下降，集合了上面两种方法的特点，更新公式如下：<br>$$<br>θ=θ−η⋅∇θJ(θ;x^{(i:i+n)};y^{(i:i+n)})<br>$$<br>这种更新方式，不像SGD一样每次更新的幅度很大，从而更易于收敛。常见的batchsize是50~256。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(nb_epochs):</div><div class="line">  np.random.shuffle(data)</div><div class="line">  <span class="keyword">for</span> batch <span class="keyword">in</span> get_batches(data, batch_size=<span class="number">50</span>):</div><div class="line">    params_grad = evaluate_gradient(loss_function, batch, params)</div><div class="line">    params = params - learning_rate * params_grad</div></pre></td></tr></table></figure>
<h2 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h2><p>学习率很难选取，太大难以收敛，太小收敛慢；变学习率的变化规则也难以适应所有数据集；此外，所有的特征不一定需要同一个学习率；最后，马鞍面产生的0梯度问题，SGD也没法解决。</p>
<h1 id="改进算法"><a href="#改进算法" class="headerlink" title="改进算法"></a>改进算法</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;梯度下降，是当下最常见的神经网络参数调优算法。当我们需要最小化目标函数$J(\theta)$时，只需要沿着目标函数梯度的$\nabla_\theta J(\theta)$反方向去更新$\theta$，就能让目标函数越来越小。如果$J(\theta)$是凸函数（二次导数非负），那最后一定能收敛到全局最小值，否则可能收敛到局部最小值。&lt;/p&gt;
    
    </summary>
    
      <category term="DeepLearning" scheme="http://github.com/categories/DeepLearning/"/>
    
    
      <category term="DeepLearning" scheme="http://github.com/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>字符编码以及python中的编码解码问题</title>
    <link href="http://github.com/2017/02/20/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/"/>
    <id>http://github.com/2017/02/20/字符编码/</id>
    <published>2017-02-20T04:20:11.000Z</published>
    <updated>2017-03-18T09:31:08.000Z</updated>
    
    <content type="html"><![CDATA[<p>计算机中，字符包括字素，类似字素的单元，可书写语言中的字母表、音节表等。例如：字母，从0到9的数字，常用标点符号，空白符，控制符等。中文的你、我、他，日文的に、ほ、ん、ご也都是字符。</p>
<a id="more"></a>
<h1 id="仓颉造字ascii码"><a href="#仓颉造字：ASCII码" class="headerlink" title="仓颉造字：ASCII码"></a>仓颉造字：ASCII码</h1><p>我们知道，八位二进制数可以表示256种状态，美国的编码标准——<strong>ASCII</strong>码，根据这一点规定了128个字符的编码，这128个符号的第一位都是0，用后七位进行编码。这128个字符一共包括：</p>
<ol>
<li>32个<strong>控制字符</strong>：0~31，如ESC，二进制表示为00011011</li>
<li><strong>空格(space)</strong>：32，二进制表示为00100000；<strong>DEL</strong>，127，二进制表示为01111111。</li>
<li><strong>标点以及运算符</strong>：33~47，58~64，91~96，123~126，如’+’表示为00101011。</li>
<li><strong>数字</strong>：48~57。</li>
<li><strong>字母</strong>：大写是65~90，小写是97~122。</li>
</ol>
<h1 id="百家争鸣其他编码"><a href="#百家争鸣：其他编码" class="headerlink" title="百家争鸣：其他编码"></a>百家争鸣：其他编码</h1><p>ASCII码只能表示128个字符，对于其他国家的语言不适用，比如法语中的é就无法用ASCII表示。于是，一些欧洲国家决定充分利用ASCII码中闲置的最高位，这样法语中的é可以编码为10000010。这样，这些欧洲国家的编码体系最多支持2^8=256个字符。</p>
<p>但是这样似乎是饮鸩止渴，不同的国家都有不同字符，如果他们都是利用ASCII码的最高位来扩展能表达的字符个数，就会遇见编码相同但代表字符不同的情况。比如法语中编码10000010代表é，而在希伯来语编码中却代表了字母Gimel (ג)，在俄语中又会代表另一个字符。</p>
<p>另外，许多国家的字符数太过于庞大了，比如汉字就多达10万左右。这个时候必须使用多个字节(一个字节8个bit)。比如，简体中文的常见编码是<strong>GB2312</strong>，使用两个字节表示一个汉字，所以理论上可以表示65536个字符。</p>
<p>注意：GB类汉字编码与后问的Unicode、UTF-8毫无关系。</p>
<h1 id="标准一统unicode"><a href="#标准一统：Unicode" class="headerlink" title="标准一统：Unicode"></a>标准一统：Unicode</h1><p>Unicode是一种统一的编码，囊括了各国所有的字符，因而也会有占用过多字节的问题存在。python中的字符串就是unicode编码，如u‘I am a string’，而我们所认为的str类型实际则是字节串。什么意思呢，如果一个字符串前面不加字母u，会被python按照默认的编码方式进行编码（encode），也叫隐式编码。linux下默认的编码方式是utf-8，windows下不是。具体参见这篇文章<a href="http://selfboot.cn/2016/12/28/py_encode_decode/" target="_blank" rel="external">Python2.x 字符编码终极指南</a>。</p>
<h1 id="发扬光大utf-8"><a href="#发扬光大：UTF-8" class="headerlink" title="发扬光大：UTF-8"></a>发扬光大：UTF-8</h1><p>utf-8是一种变字长的编码方式，解决了刚才提到的unicode的浪费内存问题，具体编码规则可以参考文章<a href="http://selfboot.cn/2014/08/28/character_encoding/#百花齐放之中文编码" target="_blank" rel="external"><strong>人机交互之字符编码</strong></a>。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;计算机中，字符包括字素，类似字素的单元，可书写语言中的字母表、音节表等。例如：字母，从0到9的数字，常用标点符号，空白符，控制符等。中文的你、我、他，日文的に、ほ、ん、ご也都是字符。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://github.com/categories/Python/"/>
    
    
      <category term="Python" scheme="http://github.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>C++之构造函数详解</title>
    <link href="http://github.com/2017/02/05/C-%E4%B9%8B%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"/>
    <id>http://github.com/2017/02/05/C-之构造函数/</id>
    <published>2017-02-05T14:24:23.000Z</published>
    <updated>2017-02-20T10:14:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h1><p>当Richard类的对象被创建时，自动调用相应的Richard()构造函数，对成员变量进行初始化，这就是构造函数。</p>
<a id="more"></a>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">class</span> <span class="title">Richard</span><span class="params">()</span></span></div><div class="line">  &#123;</div><div class="line">    <span class="keyword">public</span>:</div><div class="line">  		Richard()</div><div class="line">          &#123;</div><div class="line">            m_val=<span class="number">1</span>;</div><div class="line">          &#125;</div><div class="line">  	<span class="keyword">private</span>:</div><div class="line">  		<span class="keyword">int</span> m_val;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h1 id="构造函数的分类"><a href="#构造函数的分类" class="headerlink" title="构造函数的分类"></a>构造函数的分类</h1><p>构造函数可以分为无参数构造函数、一般构造函数、拷贝构造函数、类型转换构造函数。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Complex </div><div class="line">&#123;         </div><div class="line"></div><div class="line"><span class="keyword">private</span> :</div><div class="line">        <span class="keyword">double</span>    m_real;</div><div class="line">        <span class="keyword">double</span>    m_imag;</div><div class="line"><span class="keyword">public</span> :</div><div class="line">		无参数；</div><div class="line">		一般；</div><div class="line">		拷贝构造；</div><div class="line">		类型转换；</div><div class="line">		等号运算符重载(不属于构造函数)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="无参数构造函数"><a href="#无参数构造函数" class="headerlink" title="无参数构造函数"></a>无参数构造函数</h2><p>如果在一个类中没有写明构造函数，系统会自动生成无参数构造函数，函数为空，什么都不做。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Complex()</div><div class="line">&#123;</div><div class="line">	m_real = <span class="number">0.0</span>;</div><div class="line">	m_imag = <span class="number">0.0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="一般构造函数"><a href="#一般构造函数" class="headerlink" title="一般构造函数"></a>一般构造函数</h2><p>一般构造函数可以有各种参数形式，一个类可以有多个一般构造函数，前提是参数的个数或者类型不同（基于c++的重载函数原理）</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Complex(<span class="keyword">double</span> real, <span class="keyword">double</span> imag)</div><div class="line">&#123;</div><div class="line">	m_real = real;</div><div class="line">	m_imag = imag;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="拷贝构造函数"><a href="#拷贝构造函数" class="headerlink" title="拷贝构造函数"></a>拷贝构造函数</h2><p>拷贝构造函数是类对象本身的引用，用于根据一个已存在的对象复制出一个心得该类对象，一般在函数中会将已存在的对象数据成员的值复制一份，到新创建的对象中。</p>
<p>若果没有显示的写出拷贝构造函数，系统会创建一个默认的，但是这是会造成浅拷贝，如需深拷贝则需自己编写。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Complex(<span class="keyword">const</span> Complex&amp; c)</div><div class="line">  &#123;</div><div class="line">    m_real = c.m_real;</div><div class="line">    m_imag = c.m_imag;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>注意：等号运算符重载和拷贝构造函数是有区别的，将=右边的本类对象的值复制给等号左边的对象，它不属于构造函数，等号左右两边的对象必须已经被创建。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Complex&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Complex&amp; rhs)</div><div class="line">  &#123;</div><div class="line">    <span class="keyword">if</span>(<span class="keyword">this</span>==&amp;rhs)</div><div class="line">      &#123;</div><div class="line">        <span class="keyword">return</span> *<span class="keyword">this</span>;</div><div class="line">      &#125;</div><div class="line">  	<span class="keyword">this</span>-&gt;m_real = rhs.m_real;</div><div class="line">  	<span class="keyword">this</span>-&gt;m_imag = rhs.m_imag;</div><div class="line">  	<span class="keyword">return</span> *<span class="keyword">this</span></div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<h2 id="类型转换构造函数"><a href="#类型转换构造函数" class="headerlink" title="类型转换构造函数"></a>类型转换构造函数</h2><p>根据一个指定的类型的对象创建一个本类的对象，例如：下面将根据一个double类型的对象创建了一个Complex对象。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Complex(<span class="keyword">double</span> r)</div><div class="line">&#123;</div><div class="line">    m_real = r;</div><div class="line">    m_imag = <span class="number">0.0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>类型转换构造函数，只能有一个参数，该参数为待转换的类型。下面举一个例子，执行语句</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Complex c2;</div><div class="line">c2 = <span class="number">5.2</span>;</div></pre></td></tr></table></figure>
<p>第一行调用无参数构造函数；第二行中，先对5.2进行doule到complex的强制转换，也就是调用类型转换构造函数，然后在调用等号赋值。</p>
<h1 id="参考阅读"><a href="#参考阅读" class="headerlink" title="参考阅读"></a>参考阅读</h1><p><a href="http://blog.csdn.net/tiantang46800/article/details/6938762" target="_blank" rel="external">c++类的构造函数详解</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;构造函数&quot;&gt;&lt;a href=&quot;#构造函数&quot; class=&quot;headerlink&quot; title=&quot;构造函数&quot;&gt;&lt;/a&gt;构造函数&lt;/h1&gt;&lt;p&gt;当Richard类的对象被创建时，自动调用相应的Richard()构造函数，对成员变量进行初始化，这就是构造函数。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="http://github.com/categories/C/"/>
    
    
      <category term="C++" scheme="http://github.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++之初始化列表</title>
    <link href="http://github.com/2017/02/03/C-%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%97%E8%A1%A8/"/>
    <id>http://github.com/2017/02/03/C-之初始化列表/</id>
    <published>2017-02-03T07:31:41.000Z</published>
    <updated>2017-02-20T10:18:28.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是初始化列表"><a href="#什么是初始化列表" class="headerlink" title="什么是初始化列表"></a>什么是初始化列表</h1><p>初始化列表是构造函数的一个组成部分，可以有可以没有，因此构造函数包括：函数体、参数列表、函数名以及初始化列表。</p>
<a id="more"></a>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> foo</div><div class="line">  &#123;</div><div class="line">    <span class="built_in">string</span> name;</div><div class="line">  	<span class="keyword">int</span> id;</div><div class="line">  	foo(<span class="built_in">string</span> s, <span class="keyword">int</span> i):name(s),id(i)&#123;&#125;;</div><div class="line">  &#125;;</div><div class="line"><span class="keyword">class</span> C: <span class="keyword">public</span> B2, <span class="keyword">public</span> B1, <span class="keyword">public</span> B3</div><div class="line">&#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    C(<span class="keyword">int</span> a, <span class="keyword">int</span> b, <span class="keyword">int</span> c, <span class="keyword">int</span> d):B1(a), memberB2(d), memberB1(c),B2(b)&#123;&#125;</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    B1 memberB1;</div><div class="line">    B2 memberB2;</div><div class="line">    B3 memberB3;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="初始化列表的作用"><a href="#初始化列表的作用" class="headerlink" title="初始化列表的作用"></a>初始化列表的作用</h1><p>初始化列表的作用是对成员变量进行赋值，当然也可以在函数体里面进行赋值操作，但是对于class类型的成员变量，用初始化列表来赋值可以减少一次默认构造的过程，从而提高性能。下面两段代码解释为什么可以减少默认构造。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> Test2</div><div class="line">&#123;</div><div class="line">    Test1 test1 ;</div><div class="line">    Test2(Test1 &amp;t1)</div><div class="line">    &#123;</div><div class="line">        test1 = t1 ;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> Test2</div><div class="line">&#123;</div><div class="line">    Test1 test1 ;</div><div class="line">    Test2(Test1 &amp;t1):test1(t1)&#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>分别执行如下代码</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Test1 t1 ;</div><div class="line"><span class="function">Test2 <span class="title">t2</span><span class="params">(t1)</span> </span>;</div></pre></td></tr></table></figure>
<p>对于第一段代码，要先初始化test1，也就是先调用类Test1的默认构造函数，然后调用赋值构造函数（等号重载）；对于第二段代码，只需要直接调用类Test1的拷贝构造函数，对test2进行初始化，因此初始化列表可以减少一次默认初始化。</p>
<h1 id="必须使用初始化列表的情况"><a href="#必须使用初始化列表的情况" class="headerlink" title="必须使用初始化列表的情况"></a>必须使用初始化列表的情况</h1><p>同时，根据上面的例子我们可以知道，当Test1类没有默认构造函数时，我们必须采用初始化列表的方式。</p>
<h1 id="阅读更多"><a href="#阅读更多" class="headerlink" title="阅读更多"></a>阅读更多</h1><p><a href="http://www.cnblogs.com/graphics/archive/2010/07/04/1770900.html" target="_blank" rel="external">C++初始化列表</a></p>
<p><a href="http://blog.csdn.net/jiangnanyouzi/article/details/3721091" target="_blank" rel="external">虚基类实现机制</a></p>
<p><a href="http://www.cnblogs.com/fzhe/archive/2012/12/25/2832250.html" target="_blank" rel="external">C++的继承与派生</a></p>
<p>PS：</p>
<p>（1）调用虚函数时，因为是动态绑定，所以根据指针指向的对象的实际类型来决定。</p>
<p>（2）调用非虚函数，静态绑定，所以根据表面上看到的类的类型来决定。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是初始化列表&quot;&gt;&lt;a href=&quot;#什么是初始化列表&quot; class=&quot;headerlink&quot; title=&quot;什么是初始化列表&quot;&gt;&lt;/a&gt;什么是初始化列表&lt;/h1&gt;&lt;p&gt;初始化列表是构造函数的一个组成部分，可以有可以没有，因此构造函数包括：函数体、参数列表、函数名以及初始化列表。&lt;/p&gt;
    
    </summary>
    
      <category term="C++" scheme="http://github.com/categories/C/"/>
    
    
      <category term="C++" scheme="http://github.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>leetcode1-20</title>
    <link href="http://github.com/2017/02/02/leetcode1-20/"/>
    <id>http://github.com/2017/02/02/leetcode1-20/</id>
    <published>2017-02-02T03:43:24.000Z</published>
    <updated>2017-02-20T10:15:02.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-two-sum"><a href="#1-Two-Sum" class="headerlink" title="1. Two Sum"></a>1. Two Sum</h1><h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><p>给定一个数组，在输入一个指定的目标值后，返回数组中相加等于目标值的两个元素的下标。</p>
<p>可以假定每个输入都有一个解，并且不能重复使用同一个的元素。</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Given nums = [2, 7, 11, 15], target = 9,</div><div class="line"></div><div class="line">Because nums[0] + nums[1] = 2 + 7 = 9,</div><div class="line">return [0, 1].</div></pre></td></tr></table></figure>
<h2 id="python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">twoSum</span><span class="params">(self, nums, target)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type nums: List[int]</div><div class="line">        :type target: int</div><div class="line">        :rtype: List[int]</div><div class="line">        """</div><div class="line">        <span class="keyword">if</span> len(nums)&lt;=<span class="number">1</span>:</div><div class="line">            <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        w_dict = &#123;&#125;</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nums)):</div><div class="line">            <span class="keyword">if</span> (target - nums[i]) <span class="keyword">in</span> w_dict:</div><div class="line">                <span class="keyword">return</span> [w_dict[target - nums[i]], i]</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                w_dict[nums[i]] = i</div></pre></td></tr></table></figure>
<h2 id="c"><a href="#C" class="headerlink" title="C++"></a>C++</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; twoSum(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target) &#123;</div><div class="line">        <span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; hash;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; result;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.size(); i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">int</span> want = target-nums[i];</div><div class="line">            <span class="keyword">if</span> (hash.find(want)!=hash.end())</div><div class="line">            &#123;</div><div class="line">                result.push_back(hash[want]);</div><div class="line">                result.push_back(i);</div><div class="line">                <span class="keyword">return</span> result;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span></div><div class="line">            hash[nums[i]]=i;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="2-add-two-numbers"><a href="#2-Add-Two-Numbers" class="headerlink" title="2. Add Two Numbers"></a>2. Add Two Numbers</h1><h2 id="描述"><a href="#描述-1" class="headerlink" title="描述"></a>描述</h2><p>给定两个非空链表，分别代表两个非负整数。其中的数字按逆序存储，每一个节点都只有一个数字。输入两个这样的链表，返回两数之和，同样用链表表示。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)</div><div class="line">Output: 7 -&gt; 0 -&gt; 8</div></pre></td></tr></table></figure>
<h2 id="python"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Definition for singly-linked list.</span></div><div class="line"><span class="comment"># class ListNode(object):</span></div><div class="line"><span class="comment">#     def __init__(self, x):</span></div><div class="line"><span class="comment">#         self.val = x</span></div><div class="line"><span class="comment">#         self.next = None</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">addTwoNumbers</span><span class="params">(self, l1, l2)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type l1: ListNode</div><div class="line">        :type l2: ListNode</div><div class="line">        :rtype: ListNode</div><div class="line">        """</div><div class="line">        up = <span class="number">0</span></div><div class="line">        ans=temp = ListNode(<span class="number">0</span>)</div><div class="line">        <span class="keyword">while</span> l1 <span class="keyword">or</span> l2 <span class="keyword">or</span> up:</div><div class="line">            v1=v2=<span class="number">0</span></div><div class="line">            <span class="keyword">if</span> l1:</div><div class="line">                v1 = l1.val</div><div class="line">                l1 = l1.next</div><div class="line">            <span class="keyword">if</span> l2:</div><div class="line">                v2 = l2.val</div><div class="line">                l2 = l2.next</div><div class="line">            up, val = divmod(v1+v2+up, <span class="number">10</span>)</div><div class="line">            temp.next = ListNode(val)</div><div class="line">            temp = temp.next</div><div class="line">        <span class="keyword">return</span> ans.next</div></pre></td></tr></table></figure>
<h2 id="c"><a href="#C-1" class="headerlink" title="C++"></a>C++</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> * Definition for singly-linked list.</div><div class="line"> * struct ListNode &#123;</div><div class="line"> *     int val;</div><div class="line"> *     ListNode *next;</div><div class="line"> *     ListNode(int x) : val(x), next(NULL) &#123;&#125;</div><div class="line"> * &#125;;</div><div class="line"> */</div><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function">ListNode* <span class="title">addTwoNumbers</span><span class="params">(ListNode* l1, ListNode* l2)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> up = <span class="number">0</span>;</div><div class="line">        <span class="function">ListNode <span class="title">ans</span><span class="params">(<span class="number">0</span>)</span></span>;</div><div class="line">        ListNode *p = &amp;ans;</div><div class="line">        <span class="keyword">while</span> (l1||l2||up)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">int</span> v1=<span class="number">0</span>,v2=<span class="number">0</span>;</div><div class="line">            <span class="keyword">if</span> (l1)</div><div class="line">            &#123;</div><div class="line">                v1=l1-&gt;val;</div><div class="line">                l1 = l1-&gt;next;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span> (l2)</div><div class="line">            &#123;</div><div class="line">                v2 = l2-&gt;val;</div><div class="line">                l2 = l2-&gt;next;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> sum = v1+v2+up;</div><div class="line">            up = sum/<span class="number">10</span>;</div><div class="line">            p-&gt;next = <span class="keyword">new</span> ListNode(sum%<span class="number">10</span>);</div><div class="line">            p = p-&gt;next;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> ans.next;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="3longest-substring-without-repeating-characters"><a href="#3-Longest-Substring-Without-Repeating-Characters" class="headerlink" title="3.Longest Substring Without Repeating Characters"></a>3.Longest Substring Without Repeating Characters</h1><p>给定一个字符串，输出它的最长无重复字符子串的长度。</p>
<p>思路是哈希表加上双指针，进行遍历。</p>
<h2 id="python"><a href="#Python-2" class="headerlink" title="Python"></a>Python</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(self, s)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type s: str</div><div class="line">        :rtype: int</div><div class="line">        """</div><div class="line">        record = &#123;&#125;</div><div class="line">        ans = j = <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</div><div class="line">            <span class="keyword">if</span> s[i] <span class="keyword">in</span> record:</div><div class="line">                b = record[s[i]]+<span class="number">1</span></div><div class="line">                <span class="keyword">for</span> jj <span class="keyword">in</span> range(j,b):</div><div class="line">                    <span class="keyword">del</span> record[s[jj]]</div><div class="line">                j=b</div><div class="line">            ans = max(ans,i-j+<span class="number">1</span>)</div><div class="line">            record[s[i]] = i</div><div class="line">        <span class="keyword">return</span> ans</div></pre></td></tr></table></figure>
<h2 id="c"><a href="#C-2" class="headerlink" title="C++"></a>C++</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> ans = <span class="number">0</span>, j=<span class="number">0</span>;</div><div class="line">        <span class="built_in">map</span>&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; record;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;s.length();i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span> (record.find(s[i])!=record.end())</div><div class="line">            &#123;</div><div class="line">                <span class="keyword">int</span> temp = record[s[i]]+<span class="number">1</span>;</div><div class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> ii=j;ii&lt;temp;ii++)</div><div class="line">                &#123;</div><div class="line">                    record.erase(record.find(s[ii]));</div><div class="line">                &#125;</div><div class="line">                j = temp;</div><div class="line">            &#125;</div><div class="line">            ans = max(ans, i-j+<span class="number">1</span>);</div><div class="line">            record[s[i]]=i;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> ans;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h1 id="4median-of-two-sorted-arrays"><a href="#4-Median-of-Two-Sorted-Arrays" class="headerlink" title="4.Median of Two Sorted Arrays"></a>4.Median of Two Sorted Arrays</h1><p>给定两个排好序的数组，寻找这两个数组的中位数。例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nums1 = [1, 3]</div><div class="line">nums2 = [2]</div><div class="line"></div><div class="line">The median is 2.0</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">nums1 = [1, 2]</div><div class="line">nums2 = [3, 4]</div><div class="line"></div><div class="line">The median is (2 + 3)/2 = 2.5</div></pre></td></tr></table></figure>
<p>思路是按照奇偶性分别进行中位数查询，查询的策略师二分搜索，代码如下。</p>
<h2 id="python"><a href="#Python-3" class="headerlink" title="Python"></a>Python</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedianSortedArrays</span><span class="params">(self, nums1, nums2)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        :type nums1: List[int]</div><div class="line">        :type nums2: List[int]</div><div class="line">        :rtype: float</div><div class="line">        """</div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">binary_search</span><span class="params">(A, B, k)</span>:</span></div><div class="line">            m = len(A)</div><div class="line">            n = len(B)</div><div class="line">            <span class="keyword">if</span> m&lt;n:</div><div class="line">                <span class="keyword">return</span> binary_search(B,A,k)</div><div class="line">            <span class="keyword">if</span> n==<span class="number">0</span>:</div><div class="line">                <span class="keyword">return</span> A[k<span class="number">-1</span>]</div><div class="line">            <span class="keyword">if</span> k==<span class="number">1</span>:</div><div class="line">                <span class="keyword">return</span> min(A[<span class="number">0</span>],B[<span class="number">0</span>])</div><div class="line">            b = min(n, k/<span class="number">2</span>)</div><div class="line">            a = k-b</div><div class="line">            <span class="keyword">if</span> A[a<span class="number">-1</span>]&lt;B[b<span class="number">-1</span>]:</div><div class="line">                <span class="keyword">return</span> binary_search(A[a:],B,k-a)</div><div class="line">            <span class="keyword">elif</span> A[a<span class="number">-1</span>]&gt;B[b<span class="number">-1</span>]:</div><div class="line">                <span class="keyword">return</span> binary_search(A,B[b:],k-b)</div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                <span class="keyword">return</span> A[a<span class="number">-1</span>]</div><div class="line">        total = len(nums1)+len(nums2)</div><div class="line">        <span class="keyword">if</span> total%<span class="number">2</span>==<span class="number">0</span>:</div><div class="line">            <span class="keyword">return</span> (binary_search(nums1, nums2, total/<span class="number">2</span>)+\</div><div class="line">                 binary_search(nums1, nums2, total/<span class="number">2</span>+<span class="number">1</span>))/<span class="number">2.0</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> binary_search(nums1, nums2, total/<span class="number">2</span>+<span class="number">1</span>)</div></pre></td></tr></table></figure>
<h2 id="c"><a href="#C-3" class="headerlink" title="C++"></a>C++</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; forward_delete(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; A, <span class="keyword">int</span> k)</div><div class="line">    &#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator it=A.begin();</div><div class="line"></div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;k;i++)</div><div class="line">        &#123;</div><div class="line">            it = A.erase(it);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> A;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">double</span> <span class="title">binary_search</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; A, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; B,<span class="keyword">int</span> k)</span></span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">int</span> m = <span class="keyword">int</span>(A.size());</div><div class="line">        <span class="keyword">int</span> n = <span class="keyword">int</span> (B.size());</div><div class="line">        <span class="keyword">if</span> (m&lt;n)</div><div class="line">            <span class="keyword">return</span> binary_search(B,A,k);</div><div class="line">        <span class="keyword">if</span> (n==<span class="number">0</span>)</div><div class="line">            <span class="keyword">return</span> A[k<span class="number">-1</span>];</div><div class="line">        <span class="keyword">if</span> (k==<span class="number">1</span>)</div><div class="line">            <span class="keyword">return</span> min(A[<span class="number">0</span>],B[<span class="number">0</span>]) ;</div><div class="line">        <span class="keyword">int</span> b = min(k/<span class="number">2</span>,n) ;</div><div class="line">        <span class="keyword">int</span> a = k-b;</div><div class="line">        <span class="keyword">if</span> (A[a<span class="number">-1</span>]&lt;B[b<span class="number">-1</span>])</div><div class="line">        &#123;</div><div class="line">            <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; C = forward_delete(A,a);</div><div class="line">            <span class="keyword">return</span> binary_search(C,B,k-a);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (A[a<span class="number">-1</span>]&gt;B[b<span class="number">-1</span>])</div><div class="line">        &#123;</div><div class="line">            <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; C = forward_delete(B,b);</div><div class="line">            <span class="keyword">return</span> binary_search(A,C,k-b);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span></div><div class="line">            <span class="keyword">return</span> A[a<span class="number">-1</span>];</div><div class="line"></div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums1, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums2)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> total = <span class="keyword">int</span>(nums1.size()+nums2.size());</div><div class="line">        <span class="keyword">if</span> (total%<span class="number">2</span>==<span class="number">0</span>)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">double</span> a = binary_search(nums1,nums2,total/<span class="number">2</span>);</div><div class="line">            <span class="keyword">double</span> b=binary_search(nums1,nums2,total/<span class="number">2</span>+<span class="number">1</span>);</div><div class="line">            <span class="keyword">return</span> (a+b)/<span class="number">2.0</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">return</span> binary_search(nums1,nums2,total/<span class="number">2</span>+<span class="number">1</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-Two-Sum&quot;&gt;&lt;a href=&quot;#1-Two-Sum&quot; class=&quot;headerlink&quot; title=&quot;1. Two Sum&quot;&gt;&lt;/a&gt;1. Two Sum&lt;/h1&gt;&lt;h2 id=&quot;描述&quot;&gt;&lt;a href=&quot;#描述&quot; class=&quot;headerlink&quot; title=&quot;描述&quot;&gt;&lt;/a&gt;描述&lt;/h2&gt;&lt;p&gt;给定一个数组，在输入一个指定的目标值后，返回数组中相加等于目标值的两个元素的下标。&lt;/p&gt;
&lt;p&gt;可以假定每个输入都有一个解，并且不能重复使用同一个的元素。&lt;/p&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="http://github.com/categories/Algorithm/"/>
    
    
      <category term="LeetCode" scheme="http://github.com/tags/LeetCode/"/>
    
      <category term="Algorithm" scheme="http://github.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Hello Hexo!</title>
    <link href="http://github.com/2017/01/19/%E4%BD%A0%E5%A5%BD%EF%BC%8CHEXO/"/>
    <id>http://github.com/2017/01/19/你好，HEXO/</id>
    <published>2017-01-19T11:58:50.000Z</published>
    <updated>2017-02-02T04:28:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>你好，欢迎来到我的技术博客，下面是本文的目录。</p>
<a id="more"></a>
<p>[TOC]</p>
<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>建这个博客的目的，目前有这么几点：记录LeetCode心得体会、记录DeepLearning和其他机器学习方法的知识总结。</p>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><h2 id="行内公式"><a href="#行内公式" class="headerlink" title="行内公式"></a>行内公式</h2><p>PS：讲真，md的语法我现在还是一脸懵逼 = =，好难啊，不过既然开始了就要坚持下去。$a^1+2=3$</p>
<h2 id="插入图片"><a href="#插入图片" class="headerlink" title="插入图片"></a>插入图片</h2><p><img src="https://ww1.sinaimg.cn/large/006y8lValy1fbzuaste9aj30j60asjsc.jpg" alt=""></p>
<h2 id="行间公式"><a href="#行间公式" class="headerlink" title="行间公式"></a>行间公式</h2><p>$$<br>e=mc^2<br>$$</p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>command+alt+c</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    print(<span class="string">"Hello world!"</span>)</div></pre></td></tr></table></figure>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><p>command+T</p>
<table>
<thead>
<tr>
<th>我是表格</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>哈哈</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;你好，欢迎来到我的技术博客，下面是本文的目录。&lt;/p&gt;
    
    </summary>
    
    
      <category term="2017寒假" scheme="http://github.com/tags/2017%E5%AF%92%E5%81%87/"/>
    
  </entry>
  
</feed>
