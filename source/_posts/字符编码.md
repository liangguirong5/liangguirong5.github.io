---
title: 字符编码以及python中的编码解码问题
tags:
  - Python
categories: Python
mathjax: true
date: 2017-02-20 12:20:11 
---

计算机中，字符包括字素，类似字素的单元，可书写语言中的字母表、音节表等。例如：字母，从0到9的数字，常用标点符号，空白符，控制符等。中文的你、我、他，日文的に、ほ、ん、ご也都是字符。

<!-- more -->

# 仓颉造字：ASCII码

我们知道，八位二进制数可以表示256种状态，美国的编码标准——**ASCII**码，根据这一点规定了128个字符的编码，这128个符号的第一位都是0，用后七位进行编码。这128个字符一共包括：

1. 32个**控制字符**：0~31，如ESC，二进制表示为00011011
2. **空格(space)**：32，二进制表示为00100000；**DEL**，127，二进制表示为01111111。
3. **标点以及运算符**：33~47，58~64，91~96，123~126，如'+'表示为00101011。
4. **数字**：48~57。
5. **字母**：大写是65~90，小写是97~122。

# 百家争鸣：其他编码

ASCII码只能表示128个字符，对于其他国家的语言不适用，比如法语中的é就无法用ASCII表示。于是，一些欧洲国家决定充分利用ASCII码中闲置的最高位，这样法语中的é可以编码为10000010。这样，这些欧洲国家的编码体系最多支持2^8=256个字符。

但是这样似乎是饮鸩止渴，不同的国家都有不同字符，如果他们都是利用ASCII码的最高位来扩展能表达的字符个数，就会遇见编码相同但代表字符不同的情况。比如法语中编码10000010代表é，而在希伯来语编码中却代表了字母Gimel (ג)，在俄语中又会代表另一个字符。

另外，许多国家的字符数太过于庞大了，比如汉字就多达10万左右。这个时候必须使用多个字节(一个字节8个bit)。比如，简体中文的常见编码是**GB2312**，使用两个字节表示一个汉字，所以理论上可以表示65536个字符。

注意：GB类汉字编码与后问的Unicode、UTF-8毫无关系。

# 标准一统：Unicode

Unicode是一种统一的编码，囊括了各国所有的字符，因而也会有占用过多字节的问题存在。python中的字符串就是unicode编码，如u‘I am a string’，而我们所认为的str类型实际则是字节串。什么意思呢，如果一个字符串前面不加字母u，会被python按照默认的编码方式进行编码（encode），也叫隐式编码。linux下默认的编码方式是utf-8，windows下不是。具体参见这篇文章[Python2.x 字符编码终极指南](http://selfboot.cn/2016/12/28/py_encode_decode/)。

# 发扬光大：UTF-8

utf-8是一种变字长的编码方式，解决了刚才提到的unicode的浪费内存问题，具体编码规则可以参考文章[**人机交互之字符编码**](http://selfboot.cn/2014/08/28/character_encoding/#百花齐放之中文编码)。

常见中文的utf-8表示是占用3个字节的，下面用python3来进行编码解码说明。

在python3中，所有字符都是默认unicode编码，例如'ABC' ,'中文'二者都是unicode编码，可以直接print()。而b'ABC', b'\xe4\xb8\xad\xe6\x96\x87'则是'ABC' ,'中文'的二进制码，用encode可以把unicode码编码成二进制码，用decode可以把二进制码，解码成自己想要的或是ASCII码或是utf-8码。

```python
>>> 'ABC'.encode('ascii')
b'ABC'
>>> '中文'.encode('utf-8')
b'\xe4\xb8\xad\xe6\x96\x87'
>>> '中文'.encode('ascii')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)
>>> b'ABC'.decode('ascii')
'ABC'
>>> b'\xe4\xb8\xad\xe6\x96\x87'.decode('utf-8')
'中文'
```

