---
title: 贝叶斯优化
tags:
  - DeepLearning
  - 模型调参
categories:
  - DeepLearning
mathjax: true
date: 2017-02-26 13:52:29
---

贝叶斯优化可以用于复杂模型的调参过程中，可以自动确定一套表现最优的模型参数。本文是对贝叶斯优化方法的浅层解读，日后填坑~

<!-- more -->

# Bayesian Optimization

当对目标函数没有封闭形式的表达，但是可以得到目标函数在采样点的观测值时，可以用贝叶斯优化来寻找目标函数的极值。

优势在于需要较少的采样点，适合观测值costly的对象。

贝叶斯优化根据下面的acqusition function来选取下一个采样点的位置:
$$
x_t=argmax_{x \in D}\mu_{t-1}(x)+\beta^{1/2}\sigma_{t-1}(x)
$$
首先用已有观测值构建高斯过程回归模型，并预测输入位置上的未知函数值服从的的高斯分布，得到该点均值和方差，即$\mu_{t-1}(x)$和$\sigma_{t-1}(x)$。上式的$\beta_t$是一个权重参数，具体设置参见论文：Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design.

这个公式描述的是，如果标准差大，表示我们对该点了解程度小，值得探索(exploration)；如果均值大，表明该点可能就是我们要找的最大值点，值得开发(exploitation)。一开始，我们的采样数据很少，算法会去采样标准差很大的点；当采样的点多了，标准差会降低，算法偏向于去均值大的点，最终收敛到全局最优值。

# Gaussian Process Regression

关于高斯过程回归的知识可以参考下面两个链接，互为补充。

[高斯过程回归](http://blog.sina.com.cn/s/blog_5033f3b40102vts4.html)

[说说高斯过程回归](http://www.kuqin.com/shuoit/20150508/345958.html)